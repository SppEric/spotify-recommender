{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01e854ba-1f4e-4e24-9808-10835720210b",
   "metadata": {
    "id": "01e854ba-1f4e-4e24-9808-10835720210b"
   },
   "source": [
    "# CS1470/2470 HW4: Language Models\n",
    "\n",
    "In this homework assignment, you will build deep learning language models. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5867603-2b77-47ea-8cdb-97fa84e1a491",
   "metadata": {
    "id": "e5867603-2b77-47ea-8cdb-97fa84e1a491"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaa7e7a-c467-4f48-9fc6-2a7d28c35eda",
   "metadata": {
    "id": "1aaa7e7a-c467-4f48-9fc6-2a7d28c35eda"
   },
   "outputs": [],
   "source": [
    "data_path = \"../data\" ## TODO: Maybe edit if need be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517f466-0b7a-4fc5-b709-dbd5eddf0fe2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2459,
     "status": "ok",
     "timestamp": 1656613551989,
     "user": {
      "displayName": "Yeunun Choo",
      "userId": "09529988632388209490"
     },
     "user_tz": 240
    },
    "id": "7517f466-0b7a-4fc5-b709-dbd5eddf0fe2",
    "outputId": "19aaec91-dcdd-46e5-abdf-b519b6df02eb"
   },
   "outputs": [],
   "source": [
    "## get the tokenized list of words from the corpus\n",
    "train_tracks_id, test_tracks_id, track_to_id, relevance_output = preprocessing.preprocess()\n",
    "\n",
    "## A useful utility for counting things\n",
    "word_counter = collections.Counter(train_tracks_id)\n",
    "\n",
    "## What are the 40 most common words?\n",
    "n_most_common = 40\n",
    "most_common_tokens, most_common_occurrences = zip(*word_counter.most_common(n_most_common))\n",
    "\n",
    "## Convert the tokens back to words so that we can see what they are\n",
    "token_to_word_dict = {i:w for w, i in track_to_id.items()}\n",
    "most_common_words = [token_to_word_dict[t] for t in most_common_tokens]\n",
    "\n",
    "print(*zip(most_common_words, most_common_occurrences), sep = \", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c58056-62d8-49ff-b046-49c12fb69062",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "executionInfo": {
     "elapsed": 602,
     "status": "ok",
     "timestamp": 1656613552588,
     "user": {
      "displayName": "Yeunun Choo",
      "userId": "09529988632388209490"
     },
     "user_tz": 240
    },
    "id": "58c58056-62d8-49ff-b046-49c12fb69062",
    "outputId": "6d940990-de75-40c1-c4ad-5faf56fa0b35"
   },
   "outputs": [],
   "source": [
    "fig_most_common, ax_top50_most_common = plt.subplots()\n",
    "ax_top50_most_common.barh(y = most_common_words,\n",
    "                          width = most_common_occurrences, \n",
    "                          height = 0.75, \n",
    "                          color = \"C0\", \n",
    "                          edgecolor = \"black\", \n",
    "                          zorder = 100)\n",
    "\n",
    "ax_top50_most_common.grid(linestyle = \"dashed\", \n",
    "                          color = \"#bfbfbf\", \n",
    "                          zorder = -100)\n",
    "\n",
    "ax_top50_most_common.set_yticks(ticks = ax_top50_most_common.get_yticks())\n",
    "ax_top50_most_common.set_yticklabels(labels = most_common_words, \n",
    "                                     fontsize = 14)\n",
    "\n",
    "ax_top50_most_common.invert_yaxis()\n",
    "## If you want log-scale \n",
    "# ax_top50_most_common.set_xscale('log')\n",
    "\n",
    "fig_most_common.set_size_inches([6, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7dd1fcec-21ed-497c-a1f3-b26255ed65c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 539706,
     "status": "ok",
     "timestamp": 1656614714354,
     "user": {
      "displayName": "Yeunun Choo",
      "userId": "09529988632388209490"
     },
     "user_tz": 240
    },
    "id": "7dd1fcec-21ed-497c-a1f3-b26255ed65c6",
    "outputId": "ea87bc66-e79d-4218-9304-c053578cb260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 620s 915ms/step - loss: 10.9135 - perplexity: 58024.1484 - val_loss: 9.7583 - val_perplexity: 18812.4570\n",
      "CPU times: total: 1h 5min 48s\n",
      "Wall time: 15min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x114dd40dfa0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import rnn\n",
    "\n",
    "train_tracks_id, test_tracks_id, track_to_id, relevance_output = preprocessing.preprocess()\n",
    "\n",
    "train_id = np.array(train_id)\n",
    "test_id  = np.array(test_id)\n",
    "X0, Y0 = train_id[:-1], train_id[1:]\n",
    "X1, Y1  = test_id[:-1],  test_id[1:]\n",
    "\n",
    "\n",
    "X0 = X0[:-(len(X0) % 20)]\n",
    "Y0 = Y0[:-(len(Y0) % 20)]\n",
    "X1 = X1[:-(len(X1) % 20)]\n",
    "Y1 = Y1[:-(len(Y1) % 20)]\n",
    "\n",
    "np.reshape(X0, (-1, 20))\n",
    "np.reshape(X1, (-1, 20))\n",
    "np.reshape(Y0, (-1, 20))\n",
    "np.reshape(Y1, (-1, 20))\n",
    "\n",
    "rnn_args = rnn.get_text_model(train_tracks_id)\n",
    "\n",
    "rnn_args.model.fit(\n",
    "    X0, Y0,\n",
    "    epochs=rnn_args.epochs,\n",
    "    batch_size=rnn_args.batch_size,\n",
    "    validation_data=(X1, Y1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8de51a2b-44e0-44c5-88ad-06cbd1d9e1d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 634,
     "status": "ok",
     "timestamp": 1656614714980,
     "user": {
      "displayName": "Yeunun Choo",
      "userId": "09529988632388209490"
     },
     "user_tz": 240
    },
    "id": "8de51a2b-44e0-44c5-88ad-06cbd1d9e1d0",
    "outputId": "30bae9cb-9be5-4da5-cdbf-e0b51943616d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say It Ain't So, Gold, Caroline, Ride, Waves, Congratulations, Congratulations, Congratulations, HUMBLE., Closer, Don't Let Me Down, Go Flex, Don't Let Me Down, Congratulations, Don't Let Me Down, Don't Let Me Down, Congratulations, Don't Let Me Down, Gold Digger, Ni**as In Paris, Congratulations\n",
      "\n",
      "Island In The Sun, Gold Digger, Ride, One Dance, Don't Let Me Down, HUMBLE., Closer, Gold, Let Me Love You, Closer, Forever, Congratulations, Closer, Congratulations, Party In The U.S.A., Closer, Caroline, Gold, Let Me Love You, Gold, Caroline\n",
      "\n",
      "Undone - The Sweater Song, Let Me Love You, Sorry, Let Me Love You, One Dance, Jungle, One Dance, Bodak Yellow, Gold, Skinny Love, Congratulations, Closer, Caroline, Don't Let Me Down, Mask Off, Don't Let Me Down, Don't Let Me Down, Mask Off, Don't Let Me Down, Go Flex, Don't Let Me Down\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Feel free to mess around with the word list to see the model try to generate sentences\n",
    "for word1 in [\"Say It Ain't So\", \"Island In The Sun\", \"Undone - The Sweater Song\"]:\n",
    "    if word1 not in vocab: print(f\"{word1} not in vocabulary\")            \n",
    "    else: rnn_args.model.generate_sentence(word1, 20, vocab, 10)\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW4_LM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('eric')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "187148e4c5ed58496f5273f307f082177127925a573279df7cfa977aab41e962"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
