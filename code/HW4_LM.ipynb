{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01e854ba-1f4e-4e24-9808-10835720210b",
   "metadata": {
    "id": "01e854ba-1f4e-4e24-9808-10835720210b"
   },
   "source": [
    "# CS1470/2470 HW4: Language Models\n",
    "\n",
    "In this homework assignment, you will build deep learning language models. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5867603-2b77-47ea-8cdb-97fa84e1a491",
   "metadata": {
    "id": "e5867603-2b77-47ea-8cdb-97fa84e1a491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.19.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing\n",
    "import rnn\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "048c1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# import   preprocess, trigram, rnn\n",
    "#%aimport preprocessing.py#, trigram, rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aaa7e7a-c467-4f48-9fc6-2a7d28c35eda",
   "metadata": {
    "id": "1aaa7e7a-c467-4f48-9fc6-2a7d28c35eda"
   },
   "outputs": [],
   "source": [
    "data_path = \"../data\" ## TODO: Maybe edit if need be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371287d3-2c38-472e-b04b-237b2aa24eb6",
   "metadata": {
    "id": "371287d3-2c38-472e-b04b-237b2aa24eb6"
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8569fa65-569c-42cc-baaa-19cc3efb3a4f",
   "metadata": {
    "id": "8569fa65-569c-42cc-baaa-19cc3efb3a4f"
   },
   "source": [
    "### Tokenized Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7ca28f-3117-4983-9db8-8a141e773af7",
   "metadata": {
    "id": "ac7ca28f-3117-4983-9db8-8a141e773af7"
   },
   "source": [
    "It is now the time for you to finish the `get_data` function in the file `preprocess.py`. Then come back to this notebook and run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7517f466-0b7a-4fc5-b709-dbd5eddf0fe2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2459,
     "status": "ok",
     "timestamp": 1656613551989,
     "user": {
      "displayName": "Yeunun Choo",
      "userId": "09529988632388209490"
     },
     "user_tz": 240
    },
    "id": "7517f466-0b7a-4fc5-b709-dbd5eddf0fe2",
    "outputId": "19aaec91-dcdd-46e5-abdf-b519b6df02eb"
   },
   "outputs": [],
   "source": [
    "# ## get the tokenized list of words from the corpus\n",
    "# train_words_tokenized, test_words_tokenized, word_to_token_dict, relevance_dictionary = preprocessing.preprocess(directory='../data_info/data/', train_test_split=0.8, k=2)\n",
    "\n",
    "# ## A useful utility for counting things\n",
    "# word_counter = collections.Counter(train_words_tokenized)\n",
    "\n",
    "# ## What are the 40 most common words?\n",
    "# n_most_common = 40\n",
    "# most_common_tokens, most_common_occurrences = zip(*word_counter.most_common(n_most_common))\n",
    "\n",
    "# ## Convert the tokens back to words so that we can see what they are\n",
    "# token_to_word_dict = {i:w for w, i in word_to_token_dict.items()}\n",
    "# most_common_words = [token_to_word_dict[t] for t in most_common_tokens]\n",
    "\n",
    "# print(*zip(most_common_words, most_common_occurrences), sep = \", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe34c845-5dc5-483c-9167-496154cef5ff",
   "metadata": {
    "id": "fe34c845-5dc5-483c-9167-496154cef5ff"
   },
   "source": [
    "Here is a histogram for you. Notice how the number of occurrences decreases exponentially. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58c58056-62d8-49ff-b046-49c12fb69062",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "executionInfo": {
     "elapsed": 602,
     "status": "ok",
     "timestamp": 1656613552588,
     "user": {
      "displayName": "Yeunun Choo",
      "userId": "09529988632388209490"
     },
     "user_tz": 240
    },
    "id": "58c58056-62d8-49ff-b046-49c12fb69062",
    "outputId": "6d940990-de75-40c1-c4ad-5faf56fa0b35"
   },
   "outputs": [],
   "source": [
    "# fig_most_common, ax_top50_most_common = plt.subplots()\n",
    "# ax_top50_most_common.barh(y = most_common_words,\n",
    "#                           width = most_common_occurrences, \n",
    "#                           height = 0.75, \n",
    "#                           color = \"C0\", \n",
    "#                           edgecolor = \"black\", \n",
    "#                           zorder = 100)\n",
    "\n",
    "# ax_top50_most_common.grid(linestyle = \"dashed\", \n",
    "#                           color = \"#bfbfbf\", \n",
    "#                           zorder = -100)\n",
    "\n",
    "# ax_top50_most_common.set_yticks(ticks = ax_top50_most_common.get_yticks())\n",
    "# ax_top50_most_common.set_yticklabels(labels = most_common_words, \n",
    "#                                      fontsize = 14)\n",
    "\n",
    "# ax_top50_most_common.invert_yaxis()\n",
    "# ## If you want log-scale \n",
    "# # ax_top50_most_common.set_xscale('log')\n",
    "\n",
    "# fig_most_common.set_size_inches([6, 12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdc0ae0-cec4-42cf-86ba-cf9c17cfcb6d",
   "metadata": {
    "id": "9fdc0ae0-cec4-42cf-86ba-cf9c17cfcb6d"
   },
   "source": [
    "### Train and Test with RNN\n",
    "\n",
    "Now you should be ready to complete every function in the file `trigram.py`. Go finish `trigram.py` and come back to here.\n",
    "\n",
    "Steps to take: \n",
    "- Load the data with `get_data`\n",
    "- Reshape the input and output data into the RNN shape\n",
    "- Initialize the model, train it, and calculate the perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dd1fcec-21ed-497c-a1f3-b26255ed65c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 539706,
     "status": "ok",
     "timestamp": 1656614714354,
     "user": {
      "displayName": "Yeunun Choo",
      "userId": "09529988632388209490"
     },
     "user_tz": 240
    },
    "id": "7dd1fcec-21ed-497c-a1f3-b26255ed65c6",
    "outputId": "ea87bc66-e79d-4218-9304-c053578cb260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "failed to allocate memory [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:15\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1185\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\keras\\engine\\training.py:853\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_function\u001b[39m(iterator):\n\u001b[0;32m    852\u001b[0m   \u001b[39m\"\"\"Runs a training execution with one step.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 853\u001b[0m   \u001b[39mreturn\u001b[39;00m step_function(\u001b[39mself\u001b[39;49m, iterator)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\keras\\engine\\training.py:842\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    839\u001b[0m   \u001b[39mreturn\u001b[39;00m outputs\n\u001b[0;32m    841\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m--> 842\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m    843\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    844\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    845\u001b[0m write_scalar_summaries(outputs, step\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39m_train_counter)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1282\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1285\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1286\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2847\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   2848\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 2849\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3630\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3631\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 3632\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:597\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    596\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\keras\\engine\\training.py:835\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m--> 835\u001b[0m   outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m    836\u001b[0m   \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m    837\u001b[0m   \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\keras\\engine\\training.py:787\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[39m# Run forward pass.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m--> 787\u001b[0m   y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(x, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    788\u001b[0m   loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_loss(\n\u001b[0;32m    789\u001b[0m       y, y_pred, sample_weight, regularization_losses\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses)\n\u001b[0;32m    790\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\keras\\engine\\base_layer.py:1037\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1035\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1040\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\browncs\\cs1470\\spotify-recommender\\code\\rnn.py:51\u001b[0m, in \u001b[0;36mMyRNN.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     48\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x)\n\u001b[0;32m     50\u001b[0m \u001b[39m# Send to sequence\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[0;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\keras\\engine\\base_layer.py:1037\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1035\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1040\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\keras\\engine\\sequential.py:383\u001b[0m, in \u001b[0;36mSequential.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m argspec:\n\u001b[0;32m    381\u001b[0m   kwargs[\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m training\n\u001b[1;32m--> 383\u001b[0m outputs \u001b[39m=\u001b[39m layer(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    385\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    386\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(SINGLE_LAYER_OUTPUT_ERROR_MSG)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\keras\\engine\\base_layer.py:1030\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(name_scope):\n\u001b[0;32m   1029\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[1;32m-> 1030\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_build(inputs)\n\u001b[0;32m   1032\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autocast:\n\u001b[0;32m   1033\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\keras\\engine\\base_layer.py:2659\u001b[0m, in \u001b[0;36mLayer._maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild, \u001b[39m'\u001b[39m\u001b[39m_is_default\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m   2655\u001b[0m   \u001b[39m# Any setup work performed only once should happen in an `init_scope`\u001b[39;00m\n\u001b[0;32m   2656\u001b[0m   \u001b[39m# to avoid creating symbolic Tensors that will later pollute any eager\u001b[39;00m\n\u001b[0;32m   2657\u001b[0m   \u001b[39m# operations.\u001b[39;00m\n\u001b[0;32m   2658\u001b[0m   \u001b[39mwith\u001b[39;00m tf_utils\u001b[39m.\u001b[39mmaybe_init_scope(\u001b[39mself\u001b[39m):\n\u001b[1;32m-> 2659\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild(input_shapes)  \u001b[39m# pylint:disable=not-callable\u001b[39;00m\n\u001b[0;32m   2660\u001b[0m \u001b[39m# We must set also ensure that the layer is marked as built, and the build\u001b[39;00m\n\u001b[0;32m   2661\u001b[0m \u001b[39m# shape is stored since user defined build functions may not be calling\u001b[39;00m\n\u001b[0;32m   2662\u001b[0m \u001b[39m# `super.build()`\u001b[39;00m\n\u001b[0;32m   2663\u001b[0m Layer\u001b[39m.\u001b[39mbuild(\u001b[39mself\u001b[39m, input_shapes)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\keras\\layers\\core.py:1178\u001b[0m, in \u001b[0;36mDense.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m   1175\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThe last dimension of the inputs to `Dense` \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1176\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mshould be defined. Found `None`.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1177\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_spec \u001b[39m=\u001b[39m InputSpec(min_ndim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, axes\u001b[39m=\u001b[39m{\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m: last_dim})\n\u001b[1;32m-> 1178\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_weight(\n\u001b[0;32m   1179\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mkernel\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m   1180\u001b[0m     shape\u001b[39m=\u001b[39;49m[last_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munits],\n\u001b[0;32m   1181\u001b[0m     initializer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_initializer,\n\u001b[0;32m   1182\u001b[0m     regularizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_regularizer,\n\u001b[0;32m   1183\u001b[0m     constraint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_constraint,\n\u001b[0;32m   1184\u001b[0m     dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[0;32m   1185\u001b[0m     trainable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1186\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[0;32m   1187\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\n\u001b[0;32m   1188\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1189\u001b[0m       shape\u001b[39m=\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits,],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1193\u001b[0m       dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype,\n\u001b[0;32m   1194\u001b[0m       trainable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\keras\\engine\\base_layer.py:647\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m     tf_logging\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    643\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m`caching_device` does not work with mixed precision API. Ignoring \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    644\u001b[0m         \u001b[39m'\u001b[39m\u001b[39muser specified `caching_device`.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    645\u001b[0m     caching_device \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 647\u001b[0m variable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_variable_with_custom_getter(\n\u001b[0;32m    648\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    649\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m    650\u001b[0m     \u001b[39m# TODO(allenl): a `make_variable` equivalent should be added as a\u001b[39;49;00m\n\u001b[0;32m    651\u001b[0m     \u001b[39m# `Trackable` method.\u001b[39;49;00m\n\u001b[0;32m    652\u001b[0m     getter\u001b[39m=\u001b[39;49mgetter,\n\u001b[0;32m    653\u001b[0m     \u001b[39m# Manage errors in Layer rather than Trackable.\u001b[39;49;00m\n\u001b[0;32m    654\u001b[0m     overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    655\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[0;32m    656\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    657\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m    658\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m    659\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[0;32m    660\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections_arg,\n\u001b[0;32m    661\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m    662\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m    663\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device)\n\u001b[0;32m    664\u001b[0m \u001b[39mif\u001b[39;00m regularizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    665\u001b[0m   \u001b[39m# TODO(fchollet): in the future, this should be handled at the\u001b[39;00m\n\u001b[0;32m    666\u001b[0m   \u001b[39m# level of variable creation, and weight regularization losses\u001b[39;00m\n\u001b[0;32m    667\u001b[0m   \u001b[39m# should be variable attributes.\u001b[39;00m\n\u001b[0;32m    668\u001b[0m   name_in_scope \u001b[39m=\u001b[39m variable\u001b[39m.\u001b[39mname[:variable\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:813\u001b[0m, in \u001b[0;36mTrackable._add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    803\u001b[0m   \u001b[39mif\u001b[39;00m (checkpoint_initializer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    804\u001b[0m       \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(initializer, CheckpointInitialValueCallable) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    805\u001b[0m            (initializer\u001b[39m.\u001b[39mrestore_uid \u001b[39m>\u001b[39m checkpoint_initializer\u001b[39m.\u001b[39mrestore_uid))):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    810\u001b[0m     \u001b[39m# then we'll catch that when we call _track_trackable. So this is\u001b[39;00m\n\u001b[0;32m    811\u001b[0m     \u001b[39m# \"best effort\" to set the initializer with the highest restore UID.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m     initializer \u001b[39m=\u001b[39m checkpoint_initializer\n\u001b[1;32m--> 813\u001b[0m new_variable \u001b[39m=\u001b[39m getter(\n\u001b[0;32m    814\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    815\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m    816\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    817\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[0;32m    818\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs_for_getter)\n\u001b[0;32m    820\u001b[0m \u001b[39m# If we set an initializer and the variable processed it, tracking will not\u001b[39;00m\n\u001b[0;32m    821\u001b[0m \u001b[39m# assign again. It will add this variable to our dependencies, and if there\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[39m# is a non-trivial restoration queued, it will handle that. This also\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[39m# handles slot variables.\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m overwrite \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(new_variable, Trackable):\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\keras\\engine\\base_layer_utils.py:117\u001b[0m, in \u001b[0;36mmake_variable\u001b[1;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[0;32m    112\u001b[0m   use_resource \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[39m# In theory, in `use_resource` is True and `collections` is empty\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39m# (that is to say, in TF2), we can use tf.Variable.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39m# However, this breaks legacy (Estimator) checkpoints\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39m# because it changes variable names. Remove this when V1 is fully deprecated.\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mVariable(\n\u001b[0;32m    118\u001b[0m     initial_value\u001b[39m=\u001b[39;49minit_val,\n\u001b[0;32m    119\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    120\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m    121\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m    122\u001b[0m     dtype\u001b[39m=\u001b[39;49mvariable_dtype,\n\u001b[0;32m    123\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m    124\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m    125\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[0;32m    126\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m    127\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m    128\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m    129\u001b[0m     shape\u001b[39m=\u001b[39;49mvariable_shape \u001b[39mif\u001b[39;49;00m variable_shape \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:266\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    265\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m VariableV1:\n\u001b[1;32m--> 266\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_v1_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    267\u001b[0m   \u001b[39melif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m Variable:\n\u001b[0;32m    268\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v2_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:212\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mif\u001b[39;00m aggregation \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m   aggregation \u001b[39m=\u001b[39m VariableAggregation\u001b[39m.\u001b[39mNONE\n\u001b[1;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m previous_getter(\n\u001b[0;32m    213\u001b[0m     initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m    214\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m    215\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m    216\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m    217\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m    218\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    219\u001b[0m     variable_def\u001b[39m=\u001b[39;49mvariable_def,\n\u001b[0;32m    220\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    221\u001b[0m     expected_shape\u001b[39m=\u001b[39;49mexpected_shape,\n\u001b[0;32m    222\u001b[0m     import_scope\u001b[39m=\u001b[39;49mimport_scope,\n\u001b[0;32m    223\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m    224\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[0;32m    225\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m    226\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m    227\u001b[0m     shape\u001b[39m=\u001b[39;49mshape)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67\u001b[0m, in \u001b[0;36m_make_getter.<locals>.getter\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetter\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mreturn\u001b[39;00m captured_getter(captured_previous, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3547\u001b[0m, in \u001b[0;36m_DefaultDistributionContext.__init__.<locals>.creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   3545\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreator\u001b[39m(next_creator, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   3546\u001b[0m   _require_strategy_scope_strategy(strategy)\n\u001b[1;32m-> 3547\u001b[0m   \u001b[39mreturn\u001b[39;00m next_creator(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67\u001b[0m, in \u001b[0;36m_make_getter.<locals>.getter\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetter\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mreturn\u001b[39;00m captured_getter(captured_previous, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3547\u001b[0m, in \u001b[0;36m_DefaultDistributionContext.__init__.<locals>.creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   3545\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreator\u001b[39m(next_creator, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   3546\u001b[0m   _require_strategy_scope_strategy(strategy)\n\u001b[1;32m-> 3547\u001b[0m   \u001b[39mreturn\u001b[39;00m next_creator(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67\u001b[0m, in \u001b[0;36m_make_getter.<locals>.getter\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetter\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mreturn\u001b[39;00m captured_getter(captured_previous, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3547\u001b[0m, in \u001b[0;36m_DefaultDistributionContext.__init__.<locals>.creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   3545\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreator\u001b[39m(next_creator, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   3546\u001b[0m   _require_strategy_scope_strategy(strategy)\n\u001b[1;32m-> 3547\u001b[0m   \u001b[39mreturn\u001b[39;00m next_creator(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:205\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call.<locals>.<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_variable_v1_call\u001b[39m(\u001b[39mcls\u001b[39m,\n\u001b[0;32m    189\u001b[0m                       initial_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    190\u001b[0m                       trainable\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m                       aggregation\u001b[39m=\u001b[39mVariableAggregation\u001b[39m.\u001b[39mNONE,\n\u001b[0;32m    203\u001b[0m                       shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    204\u001b[0m   \u001b[39m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 205\u001b[0m   previous_getter \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: default_variable_creator(\u001b[39mNone\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    206\u001b[0m   \u001b[39mfor\u001b[39;00m _, getter \u001b[39min\u001b[39;00m ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39m_variable_creator_stack:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    207\u001b[0m     previous_getter \u001b[39m=\u001b[39m _make_getter(getter, previous_getter)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py:2612\u001b[0m, in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2610\u001b[0m \u001b[39mif\u001b[39;00m use_resource:\n\u001b[0;32m   2611\u001b[0m   distribute_strategy \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdistribute_strategy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 2612\u001b[0m   \u001b[39mreturn\u001b[39;00m resource_variable_ops\u001b[39m.\u001b[39;49mResourceVariable(\n\u001b[0;32m   2613\u001b[0m       initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m   2614\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m   2615\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m   2616\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m   2617\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m   2618\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   2619\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   2620\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m   2621\u001b[0m       variable_def\u001b[39m=\u001b[39;49mvariable_def,\n\u001b[0;32m   2622\u001b[0m       import_scope\u001b[39m=\u001b[39;49mimport_scope,\n\u001b[0;32m   2623\u001b[0m       distribute_strategy\u001b[39m=\u001b[39;49mdistribute_strategy,\n\u001b[0;32m   2624\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m   2625\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m   2626\u001b[0m       shape\u001b[39m=\u001b[39;49mshape)\n\u001b[0;32m   2627\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2628\u001b[0m   \u001b[39mreturn\u001b[39;00m variables\u001b[39m.\u001b[39mRefVariable(\n\u001b[0;32m   2629\u001b[0m       initial_value\u001b[39m=\u001b[39minitial_value,\n\u001b[0;32m   2630\u001b[0m       trainable\u001b[39m=\u001b[39mtrainable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2641\u001b[0m       aggregation\u001b[39m=\u001b[39maggregation,\n\u001b[0;32m   2642\u001b[0m       shape\u001b[39m=\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:270\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v2_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    269\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(VariableMetaclass, \u001b[39mcls\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1602\u001b[0m, in \u001b[0;36mResourceVariable.__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1600\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_proto(variable_def, import_scope\u001b[39m=\u001b[39mimport_scope)\n\u001b[0;32m   1601\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1602\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_from_args(\n\u001b[0;32m   1603\u001b[0m       initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m   1604\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m   1605\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m   1606\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m   1607\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1608\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1609\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m   1610\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m   1611\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m   1612\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m   1613\u001b[0m       distribute_strategy\u001b[39m=\u001b[39;49mdistribute_strategy)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1740\u001b[0m, in \u001b[0;36mResourceVariable._init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[0;32m   1738\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mInitializer\u001b[39m\u001b[39m\"\u001b[39m), device_context_manager(\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1739\u001b[0m   \u001b[39mif\u001b[39;00m init_from_fn:\n\u001b[1;32m-> 1740\u001b[0m     initial_value \u001b[39m=\u001b[39m initial_value()\n\u001b[0;32m   1741\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(initial_value, trackable\u001b[39m.\u001b[39mCheckpointInitialValue):\n\u001b[0;32m   1742\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_initialize_trackable()\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:517\u001b[0m, in \u001b[0;36mVarianceScaling.__call__\u001b[1;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    516\u001b[0m   limit \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39msqrt(\u001b[39m3.0\u001b[39m \u001b[39m*\u001b[39m scale)\n\u001b[1;32m--> 517\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_random_generator\u001b[39m.\u001b[39;49mrandom_uniform(shape, \u001b[39m-\u001b[39;49mlimit, limit, dtype)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:972\u001b[0m, in \u001b[0;36m_RandomGenerator.random_uniform\u001b[1;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    971\u001b[0m   op \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform\n\u001b[1;32m--> 972\u001b[0m \u001b[39mreturn\u001b[39;00m op(\n\u001b[0;32m    973\u001b[0m     shape\u001b[39m=\u001b[39;49mshape, minval\u001b[39m=\u001b[39;49mminval, maxval\u001b[39m=\u001b[39;49mmaxval, dtype\u001b[39m=\u001b[39;49mdtype, seed\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseed)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py:315\u001b[0m, in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[0;32m    313\u001b[0m       result \u001b[39m=\u001b[39m math_ops\u001b[39m.\u001b[39mmultiply(result, maxval)\n\u001b[0;32m    314\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 315\u001b[0m     result \u001b[39m=\u001b[39m math_ops\u001b[39m.\u001b[39madd(result \u001b[39m*\u001b[39;49m (maxval \u001b[39m-\u001b[39;49m minval), minval, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m    316\u001b[0m \u001b[39m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39m# cross FuncGraph boundaries since that information is only available in\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[39m# python. So we manually get the static shape using\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[39m# `constant_value_as_shape` which *does* cross function boundaries.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m tensor_util\u001b[39m.\u001b[39mmaybe_set_static_shape(result, shape)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1367\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1362\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1363\u001b[0m   \u001b[39m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[0;32m   1364\u001b[0m   \u001b[39m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[0;32m   1365\u001b[0m   \u001b[39m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[0;32m   1366\u001b[0m   x, y \u001b[39m=\u001b[39m maybe_promote_tensors(x, y, force_same_dtype\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1367\u001b[0m   \u001b[39mreturn\u001b[39;00m func(x, y, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1368\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1369\u001b[0m   \u001b[39m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[0;32m   1370\u001b[0m   \u001b[39m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1373\u001b[0m   \u001b[39m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m   \u001b[39m# informative.\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mtype\u001b[39m(y), \u001b[39m\"\u001b[39m\u001b[39m__r\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m op_name):\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1710\u001b[0m, in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1708\u001b[0m   \u001b[39mreturn\u001b[39;00m sparse_tensor\u001b[39m.\u001b[39mSparseTensor(y\u001b[39m.\u001b[39mindices, new_vals, y\u001b[39m.\u001b[39mdense_shape)\n\u001b[0;32m   1709\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1710\u001b[0m   \u001b[39mreturn\u001b[39;00m multiply(x, y, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:530\u001b[0m, in \u001b[0;36mmultiply\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.multiply\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmultiply\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    483\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m    484\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmultiply\u001b[39m(x, y, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    485\u001b[0m   \u001b[39m\"\"\"Returns an element-wise x * y.\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \n\u001b[0;32m    487\u001b[0m \u001b[39m  For example:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[39m   * InvalidArgumentError: When `x` and `y` have incompatible shapes or types.\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 530\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49mmul(x, y, name)\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6235\u001b[0m, in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6233\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   6234\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 6235\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[0;32m   6236\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[0;32m   6237\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ericj\\miniconda3\\envs\\DL3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6941\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m message \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6940\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 6941\u001b[0m six\u001b[39m.\u001b[39;49mraise_from(core\u001b[39m.\u001b[39;49m_status_to_exception(e\u001b[39m.\u001b[39;49mcode, message), \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: failed to allocate memory [Op:Mul]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import rnn\n",
    "\n",
    "train_id, test_id, vocab, relevance, lp = preprocessing.preprocess(directory='../data_info/data/', train_test_split=0.8, k=3)\n",
    "\n",
    "train_id = np.array(train_id)\n",
    "test_id  = np.array(test_id)    \n",
    "\n",
    "# Training and validation are aligned because we require the input song for RPrecision\n",
    "X0, Y0 = train_id, train_id\n",
    "X1, Y1 = test_id,  test_id\n",
    "\n",
    "## TODO: Get your model that you'd like to use\n",
    "args = rnn.get_text_model(vocab, relevance)\n",
    "\n",
    "data = args.model.fit(\n",
    "    X0, Y0,\n",
    "    epochs=2, \n",
    "    batch_size=lp,\n",
    "    validation_data=(X1, Y1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8ef199-d1c1-465c-b629-9d3d8cf8e1f1",
   "metadata": {
    "id": "1a8ef199-d1c1-465c-b629-9d3d8cf8e1f1"
   },
   "source": [
    "### Generate Sentences with RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc93c257-6c85-494d-9bb3-fdd28b5fe403",
   "metadata": {
    "id": "dc93c257-6c85-494d-9bb3-fdd28b5fe403"
   },
   "source": [
    "Try the model with your own pairs of starting words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8de51a2b-44e0-44c5-88ad-06cbd1d9e1d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 634,
     "status": "ok",
     "timestamp": 1656614714980,
     "user": {
      "displayName": "Yeunun Choo",
      "userId": "09529988632388209490"
     },
     "user_tz": 240
    },
    "id": "8de51a2b-44e0-44c5-88ad-06cbd1d9e1d0",
    "outputId": "30bae9cb-9be5-4da5-cdbf-e0b51943616d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alone', 'Let It Go', 'Stay With Me', \"Can't Hold Us - feat. Ray Dalton\", 'Unforgettable', 'New Americana', 'Skinny Love', 'Magnolia', 'Sorry Not Sorry', 'Closer']\n",
      "\n",
      "['Closer', 'Let Me Love You', 'One Dance', 'Cold Water (feat. Justin Bieber & MØ)', 'Broccoli (feat. Lil Yachty)', 'Roses', \"Don't Let Me Down\", 'Sorry', 'Starboy', 'This Is What You Came For', 'Work from Home', 'I Took A Pill In Ibiza - Seeb Remix', 'Gold', 'Never Be Like You', 'Panda', 'Shape of You', 'Trap Queen', 'Paris', 'Ride', 'No Problem (feat. Lil Wayne & 2 Chainz)', 'CAN\\'T STOP THE FEELING! (Original Song from DreamWorks Animation\\'s \"TROLLS\")', 'Heathens', 'Black Beatles', 'Stay', 'Jumpman', 'The Hills', 'Starving', 'In the Name of Love', 'Work', 'Hands To Myself']\n",
      "\n",
      "R-Precision: 0.1\n"
     ]
    }
   ],
   "source": [
    "def RPrecision(predictions, labels):\n",
    "        PAD_TOKEN = 0\n",
    "        #print(prediction_arr)\n",
    "        predict_set = set(predictions)\n",
    "        labels = labels[:len(predict_set)]\n",
    "        \n",
    "        ground_truth = set(labels)\n",
    "\n",
    "        # Return mean of running total to get running mean\n",
    "        return len(predict_set.intersection(ground_truth)) / len(ground_truth)\n",
    "\n",
    "## Feel free to mess around with the word list to see the model try to generate sentences\n",
    "for word1 in ['Closer']:\n",
    "    if word1 not in vocab: print(f\"{word1} not in vocabulary\")            \n",
    "    else: print(args.model.generate_recommendations(word1, 10, vocab))\n",
    "    print()\n",
    "\n",
    "ids = relevance[vocab['Closer']]\n",
    "id_to_track = {id: name for name, id in vocab.items()}\n",
    "tracks =[id_to_track[id] for id in ids]\n",
    "print(tracks[:30])\n",
    "print()\n",
    "print(\"R-Precision: \" + str(RPrecision(args.model.generate_recommendations(word1, 10, vocab), [id_to_track[x] for x in relevance[vocab['Closer']]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324df6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW4_LM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('DL3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fe492e72bd6773a3d314429fde4bd4e4bef6908777b5df5ebc6c0b18c57bf3fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
