{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "591fe09b-fa84-47b8-999c-511cd678fea4",
   "metadata": {
    "id": "591fe09b-fa84-47b8-999c-511cd678fea4"
   },
   "source": [
    "# Gated Recurrent Unit Networks\n",
    "\n",
    "In this additional challenge, students will build their own GRU layer from scratch.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc77d1bb-cea8-4532-b4c7-392f6be47723",
   "metadata": {
    "id": "bc77d1bb-cea8-4532-b4c7-392f6be47723"
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from preprocess import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dce7b3e2-4af8-4e5e-9f66-c582e5ae9d26",
   "metadata": {
    "id": "dce7b3e2-4af8-4e5e-9f66-c582e5ae9d26"
   },
   "outputs": [],
   "source": [
    "data_path = \"../../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e212c2-fc87-4de7-b15d-0b28225b1b83",
   "metadata": {
    "id": "55e212c2-fc87-4de7-b15d-0b28225b1b83"
   },
   "source": [
    "## Toy Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acafb39f-917e-4a94-a9be-df97259cde4f",
   "metadata": {
    "id": "acafb39f-917e-4a94-a9be-df97259cde4f"
   },
   "source": [
    "No spoilers for the preprocessing part of the homework here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1e9e566-1b58-4d6d-ae6c-cc53b003fabc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1656624749106,
     "user": {
      "displayName": "Yeunun Choo",
      "userId": "09529988632388209490"
     },
     "user_tz": 240
    },
    "id": "a1e9e566-1b58-4d6d-ae6c-cc53b003fabc",
    "outputId": "809b5f8f-e8da-4699-e81b-24f107fbbf1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. example_sentence_list        \n",
      "\t['the', 'word', '<_unk>', 'is', 'not', 'a', 'common', 'word', 'but', 'flower', 'is', 'a', 'common', 'word']\n",
      "\n",
      "2. example_unique_words         \n",
      "\t['<_unk>', 'a', 'but', 'common', 'flower', 'is', 'not', 'the', 'word']\n",
      "\n",
      "3. example_w2t_dict             \n",
      "\t{'<_unk>': 0, 'a': 1, 'but': 2, 'common': 3, 'flower': 4, 'is': 5, 'not': 6, 'the': 7, 'word': 8}\n",
      "\n",
      "4. example_sentence_tokenized   \n",
      "\t[7, 8, 0, 5, 6, 1, 3, 8, 2, 4, 5, 1, 3, 8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_sentence = \"The word <_UNK> is not a common word but flower is a common word\"\n",
    "\n",
    "example_sentence_list = [\n",
    "    'the', 'word', '<_unk>', 'is', 'not', \n",
    "    'a', 'common', 'word', 'but', 'flower', \n",
    "    'is', 'a', 'common', 'word']\n",
    "example_unique_words = [\n",
    "    '<_unk>', 'a', 'but', 'common', \n",
    "    'flower', 'is', 'not', 'the', 'word']\n",
    "example_w2t_dict = {\n",
    "    '<_unk>': 0, 'a': 1, 'but': 2, 'common': 3, 'flower': 4, \n",
    "    'is': 5, 'not': 6, 'the': 7, 'word': 8}\n",
    "example_sentence_tokenized = [7, 8, 0, 5, 6, 1, 3, 8, 2, 4, 5, 1, 3, 8]\n",
    "\n",
    "print(f\"1. example_sentence_list        \\n\\t{example_sentence_list}\\n\")\n",
    "print(f\"2. example_unique_words         \\n\\t{example_unique_words}\\n\")\n",
    "print(f\"3. example_w2t_dict             \\n\\t{example_w2t_dict}\\n\")\n",
    "print(f\"4. example_sentence_tokenized   \\n\\t{example_sentence_tokenized}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "662ed85e-ca14-4e48-a46d-e5b2ebd4e286",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 147,
     "status": "ok",
     "timestamp": 1656624749251,
     "user": {
      "displayName": "Yeunun Choo",
      "userId": "09529988632388209490"
     },
     "user_tz": 240
    },
    "id": "662ed85e-ca14-4e48-a46d-e5b2ebd4e286",
    "outputId": "f2418c8f-9c80-4d30-8b38-1fb4631799ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_RNN shape = (3, 4)\n",
      "y_RNN shape = (3, 4)\n",
      "X_RNN     --> y_RNN\n",
      "[7 8 0 5] --> [8 0 5 6]\n",
      "[6 1 3 8] --> [1 3 8 2]\n",
      "[2 4 5 1] --> [4 5 1 3]\n"
     ]
    }
   ],
   "source": [
    "X_RNN = np.array([\n",
    "    [7, 8, 0, 5],\n",
    "    [6, 1, 3, 8],\n",
    "    [2, 4, 5, 1]])\n",
    "y_RNN = np.array([\n",
    "    [8, 0, 5, 6],\n",
    "    [1, 3, 8, 2],\n",
    "    [4, 5, 1, 3]])\n",
    "\n",
    "print(f\"X_RNN shape = {X_RNN.shape}\")\n",
    "print(f\"y_RNN shape = {y_RNN.shape}\")\n",
    "\n",
    "print(f\"X_RNN     --> y_RNN\")\n",
    "for each_X, each_y in zip(X_RNN, y_RNN):\n",
    "    print(f\"{each_X} --> {each_y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edefc96-2073-4618-b3e7-b792f0615b0e",
   "metadata": {
    "id": "9edefc96-2073-4618-b3e7-b792f0615b0e"
   },
   "source": [
    "## Keras GRU Layer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba1ad7-6def-40e9-8ab6-ea5dcc45ef67",
   "metadata": {
    "id": "d8ba1ad7-6def-40e9-8ab6-ea5dcc45ef67"
   },
   "source": [
    "We've already looked at `tf.keras.layers.GRU`'s API. \n",
    "\n",
    "- The Keras GRU Layer expects the input shape to be in the **batch-major form**, `[batch, timesteps, embedding]`. \n",
    "- In our language model, `timesteps` is basically our `window`. \n",
    "  - That's because we treat a sequence of words as a time-series data.\n",
    "\n",
    "Also, the most important keywards arguments are `units`, `return_state` and `return_sequences`. \n",
    "- `units` is the output embedding size, \n",
    "- `return_state` and `return_sequences` are the Boolean variables to return the final state and the sequences of outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5b4cbb5-5635-4632-8365-228a60f95241",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1656624749503,
     "user": {
      "displayName": "Yeunun Choo",
      "userId": "09529988632388209490"
     },
     "user_tz": 240
    },
    "id": "a5b4cbb5-5635-4632-8365-228a60f95241",
    "outputId": "5c920556-40d4-4026-edd5-0d66a15bea8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN input tokens shape = (3, 4)\n",
      "RNN embeddings shape   = (3, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(input_dim  = 9, \n",
    "                                            output_dim = 2)\n",
    "\n",
    "X_RNN_embedding = embedding_layer(X_RNN)\n",
    "batch_size, window_size, embedding_size= X_RNN_embedding.shape ## (3, 4, 2)\n",
    "print(f\"RNN input tokens shape = {X_RNN.shape}\")\n",
    "print(f\"RNN embeddings shape   = {X_RNN_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a12a3-4e30-491f-baf1-1972d9703568",
   "metadata": {
    "id": "fc7a12a3-4e30-491f-baf1-1972d9703568"
   },
   "source": [
    "We also know that all Keras LSTM layers have the same weight structures, no matter the value of the Boolean flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "610b5e72-9d07-4c42-859d-cd6a38cdb973",
   "metadata": {
    "id": "610b5e72-9d07-4c42-859d-cd6a38cdb973"
   },
   "outputs": [],
   "source": [
    "gru           = tf.keras.layers.GRU(units=embedding_size, return_sequences=False, return_state=False)\n",
    "gru_state     = tf.keras.layers.GRU(units=embedding_size, return_sequences=False, return_state=True )\n",
    "gru_seq       = tf.keras.layers.GRU(units=embedding_size, return_sequences=True,  return_state=False)\n",
    "gru_seq_state = tf.keras.layers.GRU(units=embedding_size, return_sequences=True,  return_state=True )\n",
    "\n",
    "# the Keras GRU layers initialize their weight \n",
    "#   not when they are declared\n",
    "#   but when they are complied\n",
    "gru.build(X_RNN_embedding.shape)\n",
    "gru_state.build(X_RNN_embedding.shape)\n",
    "gru_seq.build(X_RNN_embedding.shape)\n",
    "gru_seq_state.build(X_RNN_embedding.shape)\n",
    "\n",
    "# Now all four layers have exact same weights\n",
    "gru_weights = gru.get_weights()\n",
    "gru_state.set_weights(gru_weights)\n",
    "gru_seq.set_weights(gru_weights)\n",
    "gru_seq_state.set_weights(gru_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dd4a1e-ef5b-431d-8918-0d8bd555ac87",
   "metadata": {
    "id": "91dd4a1e-ef5b-431d-8918-0d8bd555ac87"
   },
   "source": [
    "### Keras GRU Layer Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ac98a-519e-48b6-94dc-c5ee6d6c40be",
   "metadata": {
    "id": "307ac98a-519e-48b6-94dc-c5ee6d6c40be"
   },
   "source": [
    "It's time to see how those weights work under the hood. \n",
    "- The GRU weights are in fact three trainable Tensor variables named `kernel`, `recurrent_kernel`, and `bias`.\n",
    "- `kernel` is the array of weights for the input\n",
    "- `recurrent_kernel` is the array of weights for the previous hidden state\n",
    "- `bias` is the array of biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9114279-f78b-450e-8348-fe4c48a50628",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1656624749740,
     "user": {
      "displayName": "Yeunun Choo",
      "userId": "09529988632388209490"
     },
     "user_tz": 240
    },
    "id": "b9114279-f78b-450e-8348-fe4c48a50628",
    "outputId": "4500cd07-5280-447e-bb4d-717bc4ea0a91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru_cell_3/kernel:0\n",
      "<tf.Variable 'gru_cell_3/kernel:0' shape=(2, 6) dtype=float32, numpy=\n",
      "array([[ 0.05832714, -0.68992317,  0.57040364, -0.38795558, -0.2540607 ,\n",
      "        -0.22202837],\n",
      "       [-0.68398845, -0.480825  ,  0.581574  , -0.60707223, -0.05047917,\n",
      "        -0.16840476]], dtype=float32)>\n",
      "\n",
      "gru_cell_3/recurrent_kernel:0\n",
      "<tf.Variable 'gru_cell_3/recurrent_kernel:0' shape=(2, 6) dtype=float32, numpy=\n",
      "array([[-0.13634515, -0.00746232,  0.66047573, -0.686234  , -0.08757258,\n",
      "         0.2579539 ],\n",
      "       [-0.02673323, -0.25105855, -0.61883086, -0.3222601 , -0.2649923 ,\n",
      "         0.6158171 ]], dtype=float32)>\n",
      "\n",
      "gru_cell_3/bias:0\n",
      "<tf.Variable 'gru_cell_3/bias:0' shape=(2, 6) dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0.]], dtype=float32)>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for each_weight_tensor in gru_seq_state.weights:\n",
    "    print(each_weight_tensor.name)\n",
    "    print(each_weight_tensor, end = \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c52aa3a-9467-4693-bf71-1df1bb731a52",
   "metadata": {
    "id": "2c52aa3a-9467-4693-bf71-1df1bb731a52"
   },
   "source": [
    "At this point, you might be wondering \n",
    "> but wait a second. Shouldn't there be **three pairs of weights and biases**, <br>\n",
    "> because there are three internal feed-forward netwroks in a GRU unit?\n",
    "\n",
    "And, you are right. There are three pairs of weights and biases for each internal feed-forward network, but the developers of TensorFlow and Keras only decided to put the weights and biases together in a different way. We can reshape them to be make it easier for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a238df20-13a5-4602-af0c-b2c666710210",
   "metadata": {
    "id": "a238df20-13a5-4602-af0c-b2c666710210"
   },
   "outputs": [],
   "source": [
    "units = embedding_size\n",
    "W, U, b = gru_weights\n",
    "\n",
    "### kernel: weights for the input vector x_{t}\n",
    "W_z, W_r, W_h = (W[:, :units], W[:, units:(2*units)], W[:, (2*units):])\n",
    "\n",
    "### recurrent kernel: weights for the previous hidden state h_{t-1}\n",
    "U_z, U_r, U_h = (U[:, :units], U[:, units:(2*units)], U[:, (2*units):])\n",
    "\n",
    "### bias \n",
    "# Keras distinguishes between the input bias and recurrent bias for more flexibility\n",
    "# but we can just add them together and treat them as a single bias\n",
    "b = tf.reduce_sum(b, axis = 0)\n",
    "b_z, b_r, b_h = (b[:units], b[units:(units*2)], b[(units*2):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00192d2-85cb-4a2f-8aee-f6c54e38b6fd",
   "metadata": {
    "id": "a00192d2-85cb-4a2f-8aee-f6c54e38b6fd"
   },
   "source": [
    "## Your Own Implementation of GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67180dbe-e8d2-43cc-a728-c3b8e8235980",
   "metadata": {
    "id": "67180dbe-e8d2-43cc-a728-c3b8e8235980"
   },
   "source": [
    "Now we can use the weights and biases $W$, $U$, and $b$ in the way that we've covered in the lecture. \n",
    "\n",
    "- $x_t$ is the current input at timestep $t$.\n",
    "- $h_{t-1}$ is the previous hidden state. \n",
    "\n",
    "\\begin{align*}\n",
    "z_t &= \\sigma \\left( W_z x_t + U_z h_{t-1} + b_z \\right) & \\textsf{Update Gate Vector}\\\\\n",
    "r_t &= \\sigma \\left( W_r x_t + U_r h_{t-1} + b_r \\right) & \\textsf{Reset Gate Vector}\\\\\n",
    "\\hat{h}_t &= \\tanh \\left( W_h x_t + r_t \\odot ( U_h h_{t-1}) + b_h \\right) & \\textsf{Candidate Activation Vector}\\\\\n",
    "h_t &= z_t \\odot h_{t-1} + (1 - z_t) \\odot \\hat{h}_t  & \\textsf{Output, Hidden State Update}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "There a a few peculiarities that you should be aware of.\n",
    "+ Usage of the update gate vector $z_t$ \n",
    "  + Different versions of GRU uses $z_t$ differently: either as a proportion of the previous hidden state to be kept or to be forgotten. \n",
    "  + The Keras version uses $z_t$ as a proportion to be kept and not forgotten. \n",
    "  + i.e. $z_t$ is mutliplied to $h_{t-1}$ element-wisely, and not $(1- z_t)$.\n",
    "+ Application of the reset gate vector $r_t$\n",
    "  + Sometimes the reset gate vector $r_t$ is applied after or before the matrix multiplication when calculating the candidate activation vector. \n",
    "  + The Keras version applies it after the matrix multiplication like $r_t \\odot ( U_h h_{t-1})$, but not before like $U_h (r_t \\odot h_{t-1})$.\n",
    "  + This Keras behavior can be toggled with the Boolean keyword argument `reset_after`.\n",
    "  + The \"before\" version is more widely used as it is based on the [latest submission](https://arxiv.org/abs/1406.1078v3) of the Cho et al. paper.\n",
    "  + The \"after\" version appears in the [first submitted draft](https://arxiv.org/abs/1406.1078v1) of the Cho et al. ppaper\n",
    "\n",
    "\n",
    "Now, your job is to finish implementing the `call` method below. \n",
    "- The inputs need to be reshaped into the time-major form `[timesteps, batch, embedding]`.\n",
    "  - This is because is parallelizing the recurrent operations through all timesteps is very difficult.\n",
    "  - So, we will use the for-loop to advance in the timestep dimension.\n",
    "  - Then, inside the for-loop, we wil use matrix multiplications for the batch of inputs in the same timestep.\n",
    "- Remember that, in a single timestep, the input data is in the matrix form with shape `[batch, embedding]`.\n",
    "  - So, do something like $Y = XW$ instead of $y_i = W x_i, i \\in \\{1, 2, 3, \\cdots\\}$.\n",
    "  - Also, the hidden and cell states are also matrices with the same shape `[batch, embedding]`.\n",
    "- You should return the whole sequence of outputs and the final hidden and cell states\n",
    "  - Like when `return_sequences = True` and `return_state = True`.\n",
    "- The outputs needs to be reshaped back into the batch-major form `[batch, timesteps, embedding]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45a705d4-2900-4c3c-99b7-41d82f20ea5a",
   "metadata": {
    "id": "45a705d4-2900-4c3c-99b7-41d82f20ea5a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MyGRU(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        self.units = units\n",
    "        super(MyGRU, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        kernel_shape = tf.TensorShape((input_shape[-1], 3*self.units))\n",
    "\n",
    "        # Create trainable weight variables for this layer.\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\",                shape=kernel_shape, dtype=tf.float32,\n",
    "            initializer=\"glorot_uniform\", trainable=True)\n",
    "        \n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            name=\"recurrent_kernel\",      shape=kernel_shape, dtype = tf.float32,\n",
    "            initializer=\"orthogonal\",     trainable=True)\n",
    "        \n",
    "        self.bias = self.add_weight(\n",
    "            name = \"bias\",                shape=kernel_shape, dtype=tf.float32,\n",
    "            initializer = \"zeros\",        trainable=True)\n",
    "        \n",
    "        # Make sure to call the `build` method at the end\n",
    "        super(MyGRU, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs, initial_state = None):\n",
    "        ## Hidden state \n",
    "        if initial_state is None:\n",
    "            ht = tf.zeros(shape=(inputs.shape[0], self.units), dtype=tf.float32)\n",
    "        else:\n",
    "            ht = tf.identity(initial_state)\n",
    "        \n",
    "        ## Weights and biases\n",
    "        W, U, b, units = self.kernel, self.recurrent_kernel, self.bias, self.units\n",
    "        W_z, W_r, W_h = (W[:, :units], W[:, units:(2*units)], W[:, (2*units):])\n",
    "        U_z, U_r, U_h = (U[:, :units], U[:, units:(2*units)], U[:, (2*units):])\n",
    "        b = tf.reduce_sum(b, axis=0)\n",
    "        b_z, b_r, b_h = (b[:units], b[units:(units*2)], b[(units*2):])\n",
    "        \n",
    "        outputs = [] ## we need the whole sequence of outputs\n",
    "        inputs_time_major = tf.transpose(inputs, perm = [1, 0, 2]) ## swap the batch and timestep axes\n",
    "\n",
    "        ## TODO: complete this for-loop, hint: the LaTeX equation cell above\n",
    "        for input_each_step in inputs_time_major:\n",
    "\n",
    "            zt = tf.sigmoid(tf.matmul(input_each_step, W_z) + tf.matmul(ht, U_z) + b_z)\n",
    "            \n",
    "            rt = tf.sigmoid(tf.matmul(input_each_step, W_r) + tf.matmul(ht, U_r) + b_r)\n",
    "            \n",
    "            hhat = tf.tanh(tf.matmul(input_each_step, W_h) + (rt * tf.matmul(ht, U_h)) + b_h)\n",
    "            \n",
    "            ht = (zt * ht) + ((1 - zt) * hhat)\n",
    "            outputs += [ht]\n",
    "        \n",
    "        ## TODO: get the whole sequence of outputs, hint: tf.stack\n",
    "        outputs = tf.stack(outputs, axis=0)\n",
    "        \n",
    "        ## TODO: swap the batch and timestep axes again, hint: tf.transpose\n",
    "        outputs = tf.transpose(outputs, perm = [1, 0, 2])\n",
    "        \n",
    "        return outputs, ht\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.units\n",
    "        return tf.TensorShape(shape)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(MyGRU, self).get_config()\n",
    "        base_config[\"units\"] = self.units\n",
    "        return base_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca63082-2d07-4905-ac5b-cd49d7acb1ef",
   "metadata": {
    "id": "0ca63082-2d07-4905-ac5b-cd49d7acb1ef"
   },
   "source": [
    "## Compare with Keras GRU Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3dfaea-0926-4674-a56b-7f27b76694c4",
   "metadata": {
    "id": "2c3dfaea-0926-4674-a56b-7f27b76694c4"
   },
   "source": [
    "Now we have to see if your GRU layer returns the exact same outputs as the Keras GRU layer. \n",
    "\n",
    "So, we will initialize your GRU layer with **the same weights** from the other Keras GRU layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82049d9e-adc7-4d89-9953-62770aea2fb3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1656624750031,
     "user": {
      "displayName": "Yeunun Choo",
      "userId": "09529988632388209490"
     },
     "user_tz": 240
    },
    "id": "82049d9e-adc7-4d89-9953-62770aea2fb3",
    "outputId": "47c9e750-53b7-45dd-d330-a077d1436b9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.05832714, -0.68992317,  0.57040364, -0.38795558, -0.2540607 ,\n",
       "         -0.22202837],\n",
       "        [-0.68398845, -0.480825  ,  0.581574  , -0.60707223, -0.05047917,\n",
       "         -0.16840476]], dtype=float32),\n",
       " array([[-0.13634515, -0.00746232,  0.66047573, -0.686234  , -0.08757258,\n",
       "          0.2579539 ],\n",
       "        [-0.02673323, -0.25105855, -0.61883086, -0.3222601 , -0.2649923 ,\n",
       "          0.6158171 ]], dtype=float32),\n",
       " array([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_gru = MyGRU(units = 2)\n",
    "my_gru.build(X_RNN_embedding.shape)\n",
    "my_gru.set_weights(gru_weights)\n",
    "my_gru.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07940745-c6d3-480e-84bd-55ef5f1c7ed5",
   "metadata": {
    "id": "07940745-c6d3-480e-84bd-55ef5f1c7ed5"
   },
   "source": [
    "Then calculate the outputs and the states from your own GRU layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69479605-3300-49a6-b2c7-4fc5f1cf1611",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 129,
     "status": "ok",
     "timestamp": 1656624750158,
     "user": {
      "displayName": "Yeunun Choo",
      "userId": "09529988632388209490"
     },
     "user_tz": 240
    },
    "id": "69479605-3300-49a6-b2c7-4fc5f1cf1611",
    "outputId": "e74ba065-ca8a-4c2d-9df0-dec2f348b07f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my output sequence, shape = (3, 4, 2) \n",
      "[[[-0.3918192  -0.108294  ]\n",
      "  [-0.18263942 -0.10252688]\n",
      "  [-0.08338009 -0.0847781 ]\n",
      "  [-0.04018079 -0.06640589]]\n",
      "\n",
      " [[-0.38411102 -0.1013144 ]\n",
      "  [-0.17905365 -0.09312271]\n",
      "  [-0.07608739 -0.07153494]\n",
      "  [-0.02918672 -0.05279309]]\n",
      "\n",
      " [[-0.38308758 -0.11583003]\n",
      "  [-0.18507229 -0.11010924]\n",
      "  [-0.08849072 -0.09101847]\n",
      "  [-0.03174312 -0.06272328]]]\n",
      "\n",
      "my final hidden state, shape = (3, 2) \n",
      "[[-0.04018079 -0.06640589]\n",
      " [-0.02918672 -0.05279309]\n",
      " [-0.03174312 -0.06272328]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random initial states\n",
    "tf_generator = tf.random.Generator.from_seed(42)\n",
    "input_state_h = tf_generator.normal(shape=(1, units))\n",
    "\n",
    "# initial states in the [batch, embedding] format\n",
    "ht = tf.repeat(input_state_h, repeats=batch_size, axis=0)\n",
    "\n",
    "my_output_seq, my_state_h = my_gru(X_RNN_embedding, initial_state = ht)\n",
    "print(f\"my output sequence, shape = {my_output_seq.shape} \\n{my_output_seq}\\n\")\n",
    "print(f\"my final hidden state, shape = {my_state_h.shape} \\n{my_state_h}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fedef693-7028-48ea-bdc7-f3ddfa7e36e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 132,
     "status": "ok",
     "timestamp": 1656624750289,
     "user": {
      "displayName": "Yeunun Choo",
      "userId": "09529988632388209490"
     },
     "user_tz": 240
    },
    "id": "fedef693-7028-48ea-bdc7-f3ddfa7e36e6",
    "outputId": "39029a2a-3aaa-411c-86ce-3100306925da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras output sequence, shape = (3, 4, 2) \n",
      "[[[-0.3918192  -0.108294  ]\n",
      "  [-0.18263942 -0.10252688]\n",
      "  [-0.08338009 -0.0847781 ]\n",
      "  [-0.04018079 -0.06640589]]\n",
      "\n",
      " [[-0.38411102 -0.1013144 ]\n",
      "  [-0.17905365 -0.09312271]\n",
      "  [-0.07608739 -0.07153494]\n",
      "  [-0.02918672 -0.05279309]]\n",
      "\n",
      " [[-0.38308758 -0.11583003]\n",
      "  [-0.18507229 -0.11010924]\n",
      "  [-0.08849072 -0.09101847]\n",
      "  [-0.03174312 -0.06272328]]]\n",
      "\n",
      "Keras final hidden state, shape = (3, 2) \n",
      "[[-0.04018079 -0.06640589]\n",
      " [-0.02918672 -0.05279309]\n",
      " [-0.03174312 -0.06272328]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keras_output_seq, keras_state_h = gru_seq_state(X_RNN_embedding, initial_state = ht)\n",
    "\n",
    "print(f\"Keras output sequence, shape = {keras_output_seq.shape} \\n{keras_output_seq}\\n\")\n",
    "print(f\"Keras final hidden state, shape = {keras_state_h.shape} \\n{keras_state_h}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990cc4f5-91c2-459b-bb33-23de5f0b0c40",
   "metadata": {
    "id": "990cc4f5-91c2-459b-bb33-23de5f0b0c40"
   },
   "source": [
    "If you have implemented your GRU layer correctly, you will have the same outputs and states within reasonable error margins for the floating point representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2d4596d-c2c2-4e57-a51d-4efa384215ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1656624750289,
     "user": {
      "displayName": "Yeunun Choo",
      "userId": "09529988632388209490"
     },
     "user_tz": 240
    },
    "id": "b2d4596d-c2c2-4e57-a51d-4efa384215ab",
    "outputId": "ca02736c-e129-4b7f-9864-a0a46c2ef9f7"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3,2) (3,4,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\calvi\\CSCI1470\\hw4-lm-CalvinWill\\code\\custom_rnns\\GRU.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/calvi/CSCI1470/hw4-lm-CalvinWill/code/custom_rnns/GRU.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39;49mallclose(my_output_seq\u001b[39m.\u001b[39;49mnumpy(), keras_output_seq\u001b[39m.\u001b[39;49mnumpy()))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/calvi/CSCI1470/hw4-lm-CalvinWill/code/custom_rnns/GRU.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mallclose(my_state_h\u001b[39m.\u001b[39mnumpy(), keras_state_h\u001b[39m.\u001b[39mnumpy()))\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mallclose\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\calvi\\miniconda3\\envs\\dl\\lib\\site-packages\\numpy\\core\\numeric.py:2265\u001b[0m, in \u001b[0;36mallclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2194\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[0;32m   2195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mallclose\u001b[39m(a, b, rtol\u001b[39m=\u001b[39m\u001b[39m1.e-5\u001b[39m, atol\u001b[39m=\u001b[39m\u001b[39m1.e-8\u001b[39m, equal_nan\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   2196\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2197\u001b[0m \u001b[39m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[0;32m   2198\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2263\u001b[0m \n\u001b[0;32m   2264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2265\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mall\u001b[39m(isclose(a, b, rtol\u001b[39m=\u001b[39;49mrtol, atol\u001b[39m=\u001b[39;49matol, equal_nan\u001b[39m=\u001b[39;49mequal_nan))\n\u001b[0;32m   2266\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(res)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36misclose\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\calvi\\miniconda3\\envs\\dl\\lib\\site-packages\\numpy\\core\\numeric.py:2375\u001b[0m, in \u001b[0;36misclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2373\u001b[0m yfin \u001b[39m=\u001b[39m isfinite(y)\n\u001b[0;32m   2374\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(xfin) \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(yfin):\n\u001b[1;32m-> 2375\u001b[0m     \u001b[39mreturn\u001b[39;00m within_tol(x, y, atol, rtol)\n\u001b[0;32m   2376\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2377\u001b[0m     finite \u001b[39m=\u001b[39m xfin \u001b[39m&\u001b[39m yfin\n",
      "File \u001b[1;32mc:\\Users\\calvi\\miniconda3\\envs\\dl\\lib\\site-packages\\numpy\\core\\numeric.py:2356\u001b[0m, in \u001b[0;36misclose.<locals>.within_tol\u001b[1;34m(x, y, atol, rtol)\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwithin_tol\u001b[39m(x, y, atol, rtol):\n\u001b[0;32m   2355\u001b[0m     \u001b[39mwith\u001b[39;00m errstate(invalid\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m-> 2356\u001b[0m         \u001b[39mreturn\u001b[39;00m less_equal(\u001b[39mabs\u001b[39m(x\u001b[39m-\u001b[39;49my), atol \u001b[39m+\u001b[39m rtol \u001b[39m*\u001b[39m \u001b[39mabs\u001b[39m(y))\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3,2) (3,4,2) "
     ]
    }
   ],
   "source": [
    "print(np.allclose(my_output_seq.numpy(), keras_output_seq.numpy()))\n",
    "print(np.allclose(my_state_h.numpy(), keras_state_h.numpy()))\n",
    "# use np.isclose for element-wise comparison"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "GRU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7702b88cad6d75597f6011cf92cdcfa745d6308cad626581b1fa8c05db9a3bbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
